{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CNN Image Classification Problem \n",
    "\n",
    "Identifying Refugee Camps in the Middle East\n",
    "\n",
    "Here the objective is to train a CNN on satellite images to identify refugee camps in the Middle East.  Here we are dealing with a real world problem and a limited amount of data.  We'll use a data augmentation feature to suplement our existing dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import itertools, functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale, LabelBinarizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Random seed for numpy\n",
    "np.random.seed(18937)\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from shutil import copy\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool, TimeoutError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to create folders and copy files \n",
    "import os\n",
    "\n",
    "\n",
    "def create_fold_dirs(output_path, num_folds):\n",
    "    \"\"\"\n",
    "    Create train and test directories in output path\n",
    "    :param output_path: Path to the output\n",
    "    :param num_folds: the number of folds\n",
    "    \"\"\"\n",
    "    for i in range(num_folds):\n",
    "        for word in [\"train\", \"test\"]:\n",
    "            os.mkdir(os.path.join(str(output_path), word + \"_fold\" + chr(65+i)))\n",
    "    \n",
    "\n",
    "def copy_file(file, source, output):\n",
    "    f = file\n",
    "    full_path = os.path.join(source, f)\n",
    "    full_output= os.path.join(output, f)\n",
    "    folder = full_output[:full_output.rfind(\"/\")]\n",
    "    if not Path(folder).exists():\n",
    "        Path(folder).mkdir()\n",
    "    if not Path(full_output).exists():\n",
    "        print(\"Copying...{}\".format(f))\n",
    "        copy(full_path, full_output)    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying...noncamp,altinozu,36.35925,36.17987-chip10.png\n",
      "Copying...noncamp,altinozu,36.35925,36.18570-chip10.png\n",
      "Copying...noncamp,altinozu,36.37371,36.19153-chip10.png\n",
      "Copying...noncamp,altinozu,36.37371,36.18570-chip10.png\n",
      "Copying...noncamp,altinozu,36.37371,36.17987-chip10.png\n",
      "Copying...noncamp,altinozu,36.36648,36.19153-chip10.png\n",
      "Copying...noncamp,altinozu,36.36648,36.18570-chip10.png\n",
      "Copying...noncamp,altinozu,36.36648,36.17987-chip10.png\n",
      "Copying...noncamp,altinozu,36.35925,36.19153-chip10.png\n",
      "Copying...noncamp,apaydin,36.35856,36.23933-chip10.png\n",
      "Copying...noncamp,apaydin,36.35855,36.23349-chip10.png\n",
      "Copying...noncamp,apaydin,36.35855,36.22766-chip10.png\n",
      "Copying...noncamp,apaydin,36.35132,36.23933-chip10.png\n",
      "Copying...noncamp,apaydin,36.35132,36.23349-chip10.png\n",
      "Copying...noncamp,apaydin,36.35132,36.22766-chip10.png\n",
      "Copying...noncamp,apaydin,36.34409,36.23933-chip10.png\n",
      "Copying...noncamp,apaydin,36.34409,36.23349-chip10.png\n",
      "Copying...noncamp,apaydin,36.34409,36.22766-chip10.png\n",
      "Copying...noncamp,islahiye,36.61137,36.97753-chip10.png\n",
      "Copying...noncamp,islahiye,36.62597,36.98920-chip10.png\n",
      "Copying...noncamp,islahiye,36.62597,36.98337-chip10.png\n",
      "Copying...noncamp,islahiye,36.62597,36.97753-chip10.png\n",
      "Copying...noncamp,islahiye,36.61867,36.98920-chip10.png\n",
      "Copying...noncamp,islahiye,36.61867,36.98337-chip10.png\n",
      "Copying...noncamp,islahiye,36.61867,36.97753-chip10.png\n",
      "Copying...noncamp,islahiye,36.61137,36.98920-chip10.png\n",
      "Copying...noncamp,islahiye,36.61137,36.98337-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.96352,37.55875-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.96352,37.55292-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.98559,37.56458-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.98559,37.55875-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.96352,37.56458-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97824,37.57041-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97088,37.55875-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97823,37.56458-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97823,37.55875-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97823,37.55292-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97088,37.57041-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97088,37.56458-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.97088,37.55292-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.96352,37.57041-chip10.png\n",
      "Copying...noncamp,kara_tepe,26.54811,39.13152-chip10.png\n",
      "Copying...noncamp,kara_tepe,26.54059,39.12569-chip10.png\n",
      "Copying...noncamp,kara_tepe,26.54059,39.13152-chip10.png\n",
      "Copying...noncamp,king_abdullah_park,36.01925,32.52987-chip10.png\n",
      "Copying...noncamp,yayladagi,36.06385,35.91109-chip10.png\n",
      "Copying...noncamp,yayladagi,36.06385,35.90526-chip10.png\n",
      "Copying...noncamp,karkamis,38.02071,36.86882-chip10.png\n",
      "Copying...noncamp,karkamis,38.02801,36.87465-chip10.png\n",
      "Copying...noncamp,karkamis,38.03530,36.88048-chip10.png\n",
      "Copying...noncamp,karkamis,38.03530,36.87465-chip10.png\n",
      "Copying...noncamp,karkamis,38.03530,36.86882-chip10.png\n",
      "Copying...noncamp,karkamis,38.02801,36.88048-chip10.png\n",
      "Copying...noncamp,karkamis,38.02800,36.86882-chip10.png\n",
      "Copying...noncamp,karkamis,38.02071,36.88048-chip10.png\n",
      "Copying...noncamp,karkamis,38.02071,36.87465-chip10.png\n",
      "Copying...noncamp,king_abdullah_park,36.02617,32.52987-chip10.png\n",
      "Copying...noncamp,king_abdullah_park,36.02617,32.52403-chip10.png\n",
      "Copying...noncamp,king_abdullah_park,36.01925,32.52403-chip10.png\n",
      "Copying...noncamp,yayladagi,36.06385,35.89942-chip10.png\n",
      "Copying...noncamp,yayladagi,36.05665,35.90526-chip10.png\n",
      "Copying...noncamp,yayladagi,36.05665,35.91109-chip10.png\n",
      "Copying...noncamp,yayladagi,36.04944,35.90526-chip10.png\n",
      "Copying...noncamp,yayladagi,36.05664,35.89942-chip10.png\n",
      "Copying...noncamp,yayladagi,36.04944,35.91109-chip10.png\n",
      "Copying...noncamp,yayladagi,36.04944,35.89942-chip10.png\n",
      "Copying...noncamp,suruc,38.56681,36.92028-chip10.png\n",
      "Copying...noncamp,suruc,38.56681,36.91445-chip10.png\n",
      "Copying...noncamp,suruc,38.56681,36.90861-chip10.png\n",
      "Copying...noncamp,suruc,38.55952,36.91445-chip10.png\n",
      "Copying...noncamp,suruc,38.55222,36.90861-chip10.png\n",
      "Copying...noncamp,suruc,38.55952,36.92028-chip10.png\n",
      "Copying...noncamp,suruc,38.55222,36.91445-chip10.png\n",
      "Copying...noncamp,suruc,38.55952,36.90861-chip10.png\n",
      "Copying...noncamp,suruc,38.55222,36.92028-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.17351,38.35624-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.17351,38.35040-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.17350,38.34457-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.17350,38.33291-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.17350,38.33874-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.17349,38.32707-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.16607,38.35624-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.16607,38.34457-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.16607,38.35040-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.16606,38.32707-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15864,38.35624-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15863,38.35040-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15119,38.33291-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15863,38.34457-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15863,38.33291-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15120,38.35040-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15120,38.35624-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15862,38.32707-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15119,38.34457-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15119,38.32707-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.15119,38.33874-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.14376,38.35624-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.14376,38.34457-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.14376,38.33874-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.14375,38.32707-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.13632,38.35624-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.14376,38.33291-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.13632,38.34457-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.13632,38.35040-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.13632,38.33874-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.12888,38.35624-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.13632,38.33291-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.12888,38.32707-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.12888,38.33874-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.12888,38.33291-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.13632,38.32707-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.12888,38.35040-chip10.png\n",
      "Copying...noncamp,malatya_beydagi,38.12888,38.34457-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.98559,37.57041-chip10.png\n",
      "Copying...noncamp,kahmanaras_turkoglu,36.98559,37.55292-chip10.png\n",
      "Copying...noncamp,kara_tepe,26.54811,39.12569-chip10.png\n"
     ]
    }
   ],
   "source": [
    "img_dir = '/dsa/home/jamgtn/experimental/data/refugee_camp_data/Noncamp'\n",
    "out_path2 = '/dsa/home/jamgtn/experimental/data/refugee_camp_data/n_test/noncamp'\n",
    "i = 0\n",
    "for filename in os.listdir(img_dir):\n",
    "    if filename.endswith(\"10.png\"): \n",
    "        copy_file(filename, img_dir, out_path2)\n",
    "        #print(os.path.join(img_dir, filename))\n",
    "        continue\n",
    "    else:\n",
    "        continue  \n",
    "\n",
    "#############################\n",
    "#    i += 1\n",
    "#    if i > 2050:\n",
    "#        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  71.   76.   68.]\n",
      "   [  68.   83.   75.]\n",
      "   [  84.   90.   77.]\n",
      "   ..., \n",
      "   [ 181.  201.  204.]\n",
      "   [ 168.  182.  184.]\n",
      "   [ 152.  167.  168.]]\n",
      "\n",
      "  [[  57.   67.   58.]\n",
      "   [  77.   84.   74.]\n",
      "   [ 103.  109.   98.]\n",
      "   ..., \n",
      "   [ 187.  204.  211.]\n",
      "   [ 187.  204.  211.]\n",
      "   [ 195.  206.  211.]]\n",
      "\n",
      "  [[  71.   76.   68.]\n",
      "   [  87.   93.   83.]\n",
      "   [ 109.  117.  106.]\n",
      "   ..., \n",
      "   [ 187.  204.  211.]\n",
      "   [ 207.  221.  227.]\n",
      "   [ 228.  237.  242.]]\n",
      "\n",
      "  ..., \n",
      "  [[ 119.  140.  147.]\n",
      "   [ 107.  131.  136.]\n",
      "   [ 119.  140.  147.]\n",
      "   ..., \n",
      "   [ 102.  124.  131.]\n",
      "   [  89.  109.  115.]\n",
      "   [ 107.  131.  136.]]\n",
      "\n",
      "  [[ 119.  140.  147.]\n",
      "   [ 102.  124.  131.]\n",
      "   [ 119.  140.  147.]\n",
      "   ..., \n",
      "   [ 102.  120.  121.]\n",
      "   [ 107.  131.  136.]\n",
      "   [ 135.  151.  152.]]\n",
      "\n",
      "  [[ 140.  163.  167.]\n",
      "   [ 137.  156.  163.]\n",
      "   [ 123.  151.  163.]\n",
      "   ..., \n",
      "   [ 102.  124.  131.]\n",
      "   [ 119.  140.  147.]\n",
      "   [ 140.  163.  167.]]]]\n",
      "(1, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# this cell is not used in the model, just here to demonstrate how datagen works.  \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/dsa/home/jamgtn/experimental/data/refugee_camp_data/n_test/noncamp/noncamp,altinozu,36.35925,36.17987-chip10.png')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "train = '/dsa/home/jamgtn/experimental/data/refugee_camp_data/train'\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=train, save_prefix='camps', save_format='png'):\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncamp,islahiye,36.61867,36.97753-chip10.png\n",
      "noncamp,kahmanaras_turkoglu,36.96352,37.56458-chip10.png\n",
      "noncamp,kahmanaras_turkoglu,36.97088,37.57041-chip10.png\n",
      "noncamp,kahmanaras_turkoglu,36.97823,37.55875-chip10.png\n",
      "noncamp,karkamis,38.03530,36.87465-chip10.png\n",
      "noncamp,malatya_beydagi,38.12888,38.35624-chip10.png\n",
      "noncamp,malatya_beydagi,38.17350,38.33291-chip10.png\n",
      "noncamp,altinozu,36.35925,36.18570-chip10.png\n",
      "noncamp,apaydin,36.34409,36.22766-chip10.png\n",
      "noncamp,king_abdullah_park,36.02617,32.52403-chip10.png\n",
      "noncamp,malatya_beydagi,38.17351,38.35624-chip10.png\n",
      "noncamp,altinozu,36.35925,36.17987-chip10.png\n",
      "noncamp,altinozu,36.37371,36.19153-chip10.png\n",
      "noncamp,malatya_beydagi,38.15863,38.34457-chip10.png\n",
      "noncamp,malatya_beydagi,38.12888,38.35040-chip10.png\n",
      "noncamp,altinozu,36.36648,36.17987-chip10.png\n",
      "noncamp,altinozu,36.37371,36.18570-chip10.png\n",
      "noncamp,apaydin,36.35132,36.23933-chip10.png\n",
      "noncamp,islahiye,36.61137,36.98337-chip10.png\n",
      "noncamp,malatya_beydagi,38.13632,38.33291-chip10.png\n",
      "noncamp,suruc,38.55222,36.92028-chip10.png\n",
      "noncamp,apaydin,36.34409,36.23933-chip10.png\n",
      "noncamp,islahiye,36.62597,36.98920-chip10.png\n",
      "noncamp,malatya_beydagi,38.14376,38.35624-chip10.png\n",
      "noncamp,islahiye,36.61867,36.98337-chip10.png\n",
      "noncamp,kahmanaras_turkoglu,36.96352,37.55875-chip10.png\n",
      "noncamp,kahmanaras_turkoglu,36.97824,37.57041-chip10.png\n",
      "noncamp,karkamis,38.02071,36.86882-chip10.png\n",
      "noncamp,malatya_beydagi,38.17349,38.32707-chip10.png\n",
      "noncamp,kahmanaras_turkoglu,36.97823,37.55292-chip10.png\n",
      "noncamp,karkamis,38.02801,36.87465-chip10.png\n",
      "noncamp,malatya_beydagi,38.15119,38.33874-chip10.png\n",
      "noncamp,yayladagi,36.06385,35.91109-chip10.png\n",
      "noncamp,king_abdullah_park,36.02617,32.52987-chip10.png\n",
      "noncamp,malatya_beydagi,38.12888,38.33291-chip10.png\n",
      "noncamp,malatya_beydagi,38.12888,38.33874-chip10.png\n",
      "noncamp,malatya_beydagi,38.16607,38.35040-chip10.png\n",
      "noncamp,yayladagi,36.06385,35.89942-chip10.png\n",
      "noncamp,malatya_beydagi,38.15862,38.32707-chip10.png\n",
      "noncamp,yayladagi,36.04944,35.91109-chip10.png\n"
     ]
    }
   ],
   "source": [
    "# let's take a peak at the files in the directory\n",
    "import os\n",
    "indir = '/dsa/home/jamgtn/experimental/data/refugee_camp_data/n_test/noncamp'\n",
    "for root, dirs, filenames in os.walk(indir):\n",
    "    for f in filenames:\n",
    "        print(f)\n",
    "\n",
    "#for root, dirs, filenames in load_img(indir):\n",
    "#    for f in filenames:\n",
    "#        print(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n",
      "(150, 150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "z = load_img('/dsa/home/jamgtn/experimental/data/refugee_camp_data/n_test/noncamp/noncamp,altinozu,36.35925,36.17987-chip10.png')  # this is a PIL image\n",
    "x = img_to_array(z)  # this is a Numpy array with shape (3, 150, 150)\n",
    "print(x.shape)\n",
    "\n",
    "n_col = x.shape\n",
    "print(n_col)\n",
    "\n",
    "xt = np.transpose(x)\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "n_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(n_col))) # n_col is defined by the shape above \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 108 images belonging to 2 classes.\n",
      "Found 51 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/dsa/home/jamgtn/experimental/data/refugee_camp_data/n_train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/dsa/home/jamgtn/experimental/data/refugee_camp_data/n_test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "180/180 [==============================] - 67s - loss: 0.2254 - acc: 0.9206 - val_loss: 0.2131 - val_acc: 0.9411\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 66s - loss: 0.0495 - acc: 0.9834 - val_loss: 0.1657 - val_acc: 0.9600\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 67s - loss: 0.0431 - acc: 0.9860 - val_loss: 0.2554 - val_acc: 0.9411\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 66s - loss: 0.0079 - acc: 0.9971 - val_loss: 0.3332 - val_acc: 0.9400\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 66s - loss: 0.0147 - acc: 0.9970 - val_loss: 0.4245 - val_acc: 0.9421\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 67s - loss: 0.0134 - acc: 0.9958 - val_loss: 0.2931 - val_acc: 0.9400\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 66s - loss: 0.0025 - acc: 0.9993 - val_loss: 0.3676 - val_acc: 0.9611\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 67s - loss: 9.9919e-04 - acc: 0.9997 - val_loss: 0.4267 - val_acc: 0.9611\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 67s - loss: 0.0025 - acc: 0.9990 - val_loss: 0.3715 - val_acc: 0.9611\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 67s - loss: 3.1442e-04 - acc: 1.0000 - val_loss: 0.4538 - val_acc: 0.9611\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 67s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4634 - val_acc: 0.9611\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 67s - loss: 0.0011 - acc: 0.9995 - val_loss: 0.5045 - val_acc: 0.9600\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 67s - loss: 6.5580e-04 - acc: 1.0000 - val_loss: 0.5005 - val_acc: 0.9621\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 67s - loss: 5.7163e-04 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.9611\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 66s - loss: 0.0404 - acc: 0.9873 - val_loss: 0.1221 - val_acc: 0.9421\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 67s - loss: 0.0486 - acc: 0.9872 - val_loss: 0.3023 - val_acc: 0.9421\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 67s - loss: 0.0037 - acc: 0.9986 - val_loss: 0.3720 - val_acc: 0.9400\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 67s - loss: 0.0022 - acc: 0.9995 - val_loss: 0.5004 - val_acc: 0.9621\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 66s - loss: 0.0030 - acc: 0.9990 - val_loss: 0.4642 - val_acc: 0.9400\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 66s - loss: 0.0018 - acc: 0.9997 - val_loss: 0.4790 - val_acc: 0.9600\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 66s - loss: 0.0018 - acc: 0.9993 - val_loss: 0.5226 - val_acc: 0.9600\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 67s - loss: 0.0196 - acc: 0.9959 - val_loss: 0.5659 - val_acc: 0.9621\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 67s - loss: 0.1798 - acc: 0.9458 - val_loss: 0.4976 - val_acc: 0.9000\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 67s - loss: 0.0147 - acc: 0.9956 - val_loss: 0.3194 - val_acc: 0.9611\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 67s - loss: 0.0019 - acc: 0.9997 - val_loss: 0.3778 - val_acc: 0.9611\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 68s - loss: 0.0017 - acc: 0.9988 - val_loss: 0.3715 - val_acc: 0.9621\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 71s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.3108 - val_acc: 0.9611\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 70s - loss: 0.0087 - acc: 0.9964 - val_loss: 0.2822 - val_acc: 0.9611\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 69s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.3208 - val_acc: 0.9611\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 68s - loss: 0.0020 - acc: 0.9993 - val_loss: 0.3804 - val_acc: 0.9600\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 67s - loss: 0.0010 - acc: 0.9997 - val_loss: 0.4365 - val_acc: 0.9411\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 67s - loss: 8.2146e-04 - acc: 0.9997 - val_loss: 0.3680 - val_acc: 0.9611\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 67s - loss: 4.9316e-04 - acc: 1.0000 - val_loss: 0.4553 - val_acc: 0.9611\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 67s - loss: 2.7456e-04 - acc: 1.0000 - val_loss: 0.4416 - val_acc: 0.9611\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 67s - loss: 0.0092 - acc: 0.9968 - val_loss: 0.2730 - val_acc: 0.9611\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 67s - loss: 0.0132 - acc: 0.9968 - val_loss: 0.3225 - val_acc: 0.9600\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 67s - loss: 0.0026 - acc: 0.9990 - val_loss: 0.3439 - val_acc: 0.9600\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 67s - loss: 4.1380e-04 - acc: 1.0000 - val_loss: 0.4226 - val_acc: 0.9611\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 67s - loss: 0.0021 - acc: 0.9990 - val_loss: 0.3451 - val_acc: 0.9600\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 66s - loss: 0.0014 - acc: 0.9993 - val_loss: 0.3914 - val_acc: 0.9600\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 66s - loss: 6.8588e-04 - acc: 0.9997 - val_loss: 0.3438 - val_acc: 0.9611\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 67s - loss: 8.1392e-05 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.9421\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 67s - loss: 0.0016 - acc: 0.9992 - val_loss: 0.3187 - val_acc: 0.9611\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 67s - loss: 0.0041 - acc: 0.9981 - val_loss: 0.4978 - val_acc: 0.9600\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 66s - loss: 0.0012 - acc: 0.9993 - val_loss: 0.5187 - val_acc: 0.9611\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 67s - loss: 5.4942e-04 - acc: 0.9997 - val_loss: 0.4740 - val_acc: 0.9611\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 66s - loss: 0.0010 - acc: 0.9993 - val_loss: 0.4814 - val_acc: 0.9421\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 66s - loss: 0.0013 - acc: 0.9997 - val_loss: 0.5289 - val_acc: 0.9411\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 67s - loss: 0.1793 - acc: 0.9382 - val_loss: 0.3872 - val_acc: 0.8421\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 67s - loss: 0.0323 - acc: 0.9800 - val_loss: 0.5576 - val_acc: 0.9221\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2881 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1184 // batch_size)\n",
    "model.save_weights('first_try.h5')  #  save weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
